{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d102836e",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "For this project, our group decided to perform an ETL process for Trending Youtube Video Statistics. Our datasets included daily trending Youtube videos in the US and CA regions as well as a dataset of various categories the videos belong to. Our ETL process seeks to read the datasets, clean up the dataset according to our standards, and load into a database. From there, we determine which video/category is the most/least popular with respect to the number of likes, dislikes, views, and comments.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff717665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from config import username, password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763401f",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "We downloaded our data from Kaggle through the following link: https://www.kaggle.com/datasnaek/youtube-new\n",
    "\n",
    "The files we specifically utilized were daily trending Youtube videos in the US and CA regions (formatted as .csv) as well as category files (formatted as .json) that details the different categories the videos belong to. The links to the files are provided below\n",
    "\n",
    "     - https://www.kaggle.com/datasnaek/youtube-new?select=CAvideos.csv\n",
    "     - https://www.kaggle.com/datasnaek/youtube-new?select=USvideos.csv\n",
    "     - https://www.kaggle.com/datasnaek/youtube-new?select=CA_category_id.json\n",
    "     - https://www.kaggle.com/datasnaek/youtube-new?select=US_category_id.json\n",
    "\n",
    "\n",
    "These files are read by the Pandas library in Jupyter Notebook for the transformation step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ba296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read resources\n",
    "CA_videos = pd.read_csv('Resources/CAvideos.csv')\n",
    "US_videos = pd.read_csv('Resources/USvideos.csv')\n",
    "CA_category_id = pd.read_json('Resources/CA_category_id.json')\n",
    "US_category_id = pd.read_json('Resources/US_category_id.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jumaan start here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569b6d4",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "\n",
    "The Pandas library was the main tool to perform data clean up/transformation. It was done so as following:\n",
    "\n",
    "    - Read the CAvideos.csv and USvideos.csv files into a pandas dataframe.\n",
    "    - Drop any unnecessary columns and rename columns for improved readability. \n",
    "    - Check for any duplicate rows that exist within the dataframe and drop them.\n",
    "    - Read the CA_category_id.json and US_category_id.json files into a pandas dataframe.\n",
    "    - Only the category_id and category_title information is necessary, so extract that from the \"items\" column of the category dataframes. \n",
    "    - Since the \"items\" column exists as a list, iterate over the list and append the various ids and titles in separate lists in order to create a new data frame.\n",
    "    - Finally, merge the CA and US videos dataframe with their respective category dataframe on category_id. Once merged, add a column for country that specifies either \"US\" or \"CA\" for each dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the columns on US_videos\n",
    "US_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b56368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns and rename\n",
    "US_videos_new = US_videos[['title', 'category_id', 'views', 'likes', 'dislikes', 'comment_count']]\n",
    "\n",
    "US_videos_new.rename(columns={\"comment_count\":\"comments\"},inplace= True)\n",
    "\n",
    "US_videos_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d55f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicates and drop any duplicate rows\n",
    "print(len(US_videos_new)) \n",
    "print(len(US_videos_new['title'].unique()))\n",
    "\n",
    "US_videos_new.drop_duplicates(subset=[\"title\"],keep = \"last\",inplace=True)\n",
    "\n",
    "print(len(US_videos_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2462eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the columns on US_category_id\n",
    "US_category_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn items column into a list\n",
    "US_category_id_list = US_category_id['items'].tolist()\n",
    "\n",
    "#Loop through the list and extract category id and title\n",
    "category_id = []\n",
    "category_title = []\n",
    "\n",
    "for category in US_category_id_list:\n",
    "    category_id.append(int(category['id']))\n",
    "    category_title.append(category['snippet']['title'])\n",
    "\n",
    "#Store the information in a datagrame\n",
    "US_categories = pd.DataFrame({\"category_title\": category_title, \"category_id\": category_id})\n",
    "\n",
    "US_categories.head()\n",
    "\n",
    "len(US_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3661911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge both dataframes on category_id\n",
    "US_merged = pd.merge(US_videos_new, US_categories, on=\"category_id\", how=\"inner\")\n",
    "US_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d815223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jumaan end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b329bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shrey start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279525ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the CAvideo file into a dataframe\n",
    "CA_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the unnecessary columns\n",
    "CA_videos_new = CA_videos[[\"title\",\"category_id\",\"views\",\"likes\",\"dislikes\",\"comment_count\"]].copy()\n",
    "CA_videos_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c0875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns\n",
    "CA_videos_new.rename(columns={\"comment_count\":\"comments\"},inplace= True)\n",
    "CA_videos_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CA_videos_new[\"title\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915572e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CA_videos_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the duplicates\n",
    "CA_videos_new.drop_duplicates(subset=[\"title\"],keep = \"last\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97955fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CA_videos_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_category_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22463f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CA_category_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_category_id[\"items\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ef492",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_list = CA_category_id[\"items\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the required information from the category dataframe\n",
    "id_list = []\n",
    "title=  []\n",
    "for item in items_list:\n",
    "    id_list.append(int(item[\"id\"]))\n",
    "    title.append(item[\"snippet\"][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c66e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the information in a dataframe\n",
    "new_category_df = pd.DataFrame({\"category_title\":title,\"category_id\":id_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d32b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_category_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294040af",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_category_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_category_df[\"category_id\"] = new_category_df[\"category_id\"].astype(int)\n",
    "new_category_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the individual country dataframes with the category dataframe\n",
    "mergedCA_df = pd.merge(CA_videos_new,new_category_df,on=\"category_id\",how=\"inner\")\n",
    "mergedCA_df\n",
    "mergedCA_df[\"country\"] = \"CA\"\n",
    "mergedCA_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedUS_df = pd.merge(US_videos_new,new_category_df,on=\"category_id\",how=\"inner\")\n",
    "mergedUS_df.dropna()\n",
    "mergedUS_df[\"country\"] = \"US\"\n",
    "mergedUS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anji start here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35d23a",
   "metadata": {},
   "source": [
    "# Loading\n",
    "\n",
    "We decided to use PostgreSQL (relational database) to load our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb5755",
   "metadata": {},
   "source": [
    "__Connect to local database__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76add69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_connection_string = f'{username}:{password}@localhost:5432/youtube_db'\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a4dc7",
   "metadata": {},
   "source": [
    "__Check for tables__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53285e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6093f",
   "metadata": {},
   "source": [
    "__Use PANDAS to load csv/json converted DataFrames into database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# US dataframe\n",
    "mergedUS_df.to_sql(name=\"merged_us\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04357c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA dataframe\n",
    "mergedCA_df.to_sql(name=\"merged_ca\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14724c",
   "metadata": {},
   "source": [
    "__Confirm data has been added by querying both tables__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32258f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"select * from merged_us\", con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219af62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"select * from merged_ca\", con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anji end here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
